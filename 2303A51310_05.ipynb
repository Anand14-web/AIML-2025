{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7nOh0imlcZKMaOu83kPZ5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anand14-web/AIML-2025/blob/main/2303A51310_05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "27. Prediction of Air Qualities in Italian Cities\n",
        "    1. Identify the top 5 reasons for air quality\n",
        "    2. Identity the Day of week with most air quantity issues\n",
        "    3.Find the max and min air quality levels\n",
        "    4. identify the highest and lowest temparatures of air quality\n",
        "    5. Identify the highest educational qualification of the employees.\n",
        "    6. Apply either Classification Model or Clusturing Model to evaluate the dataset"
      ],
      "metadata": {
        "id": "RODuBhAEmwM8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.)\n",
        "To predict air quality in Italian cities, you can analyze air quality data and identify factors influencing air quality. The top 5 reasons for air quality degradation typically include:\n",
        "\n",
        "    1.Vehicular Emissions: High vehicle density leads to significant pollutant emissions (e.g., NOx, CO, and particulate matter).\n",
        "    2.Industrial Emissions: Factories and industries emit pollutants, especially in areas with manufacturing plants.\n",
        "    3.Domestic Heating: Wood and coal-based heating systems contribute to particulate matter.\n",
        "    4.Geography and Weather: Geographical factors (like valleys) and weather conditions (low wind speeds, temperature inversions) trap pollutants.\n",
        "    5.Agricultural Practices: Use of fertilizers and burning of crop residues can release harmful chemicals into the air."
      ],
      "metadata": {
        "id": "WMEbhKDipBhY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ucimlrepo\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "air_quality = fetch_ucirepo(id=360)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = air_quality.data.features\n",
        "y = air_quality.data.targets\n",
        "\n",
        "# metadata\n",
        "print(air_quality.metadata)\n",
        "\n",
        "# variable information\n",
        "print(air_quality.variables)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNKayTicq0G6",
        "outputId": "0efeacd5-4463-4aad-d08d-5e3635cb2139"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2024.8.30)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n",
            "{'uci_id': 360, 'name': 'Air Quality', 'repository_url': 'https://archive.ics.uci.edu/dataset/360/air+quality', 'data_url': 'https://archive.ics.uci.edu/static/public/360/data.csv', 'abstract': 'Contains the responses of a gas multisensor device deployed on the field in an Italian city. Hourly responses averages are recorded along with gas concentrations references from a certified analyzer. ', 'area': 'Computer Science', 'tasks': ['Regression'], 'characteristics': ['Multivariate', 'Time-Series'], 'num_instances': 9358, 'num_features': 15, 'feature_types': ['Real'], 'demographics': [], 'target_col': None, 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2008, 'last_updated': 'Sun Mar 10 2024', 'dataset_doi': '10.24432/C59K5F', 'creators': ['Saverio Vito'], 'intro_paper': {'ID': 420, 'type': 'NATIVE', 'title': 'On field calibration of an electronic nose for benzene estimation in an urban pollution monitoring scenario', 'authors': 'S. D. Vito, E. Massera, M. Piga, L. Martinotto, G. Francia', 'venue': 'Sensors and Actuators B: Chemical', 'year': 2008, 'journal': None, 'DOI': '10.1016/j.snb.2007.09.060', 'URL': 'https://www.semanticscholar.org/paper/a90a54a39ff934772df57771a0012981f355949d', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'The dataset contains 9358 instances of hourly averaged responses from an array of 5 metal oxide chemical sensors embedded in an Air Quality Chemical Multisensor Device. The device was located on the field in a significantly polluted area, at road level,within an Italian city. Data were recorded from March 2004 to February 2005 (one year)representing the longest freely available recordings of on field deployed air quality chemical sensor devices responses. Ground Truth hourly averaged concentrations for CO, Non Metanic Hydrocarbons, Benzene, Total Nitrogen Oxides (NOx) and Nitrogen Dioxide (NO2)  and were provided by a co-located reference certified analyzer. Evidences of cross-sensitivities as well as both concept and sensor drifts are present as described in De Vito et al., Sens. And Act. B, Vol. 129,2,2008 (citation required) eventually affecting sensors concentration estimation capabilities. Missing values are tagged with -200 value.\\r\\nThis dataset can be used exclusively for research purposes. Commercial purposes are fully excluded.\\r\\n', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': '0 Date\\t(DD/MM/YYYY)\\r\\n1 Time\\t(HH.MM.SS)\\r\\n2 True hourly averaged concentration CO in mg/m^3  (reference analyzer)\\r\\n3 PT08.S1 (tin oxide)  hourly averaged sensor response (nominally  CO targeted)\\t\\r\\n4 True hourly averaged overall Non Metanic HydroCarbons concentration in microg/m^3 (reference analyzer)\\r\\n5 True hourly averaged Benzene concentration  in microg/m^3 (reference analyzer)\\r\\n6 PT08.S2 (titania) hourly averaged sensor response (nominally NMHC targeted)\\t\\r\\n7 True hourly averaged NOx concentration  in ppb (reference analyzer)\\r\\n8 PT08.S3 (tungsten oxide) hourly averaged sensor response (nominally NOx targeted) \\r\\n9 True hourly averaged NO2 concentration in microg/m^3 (reference analyzer)\\t\\r\\n10 PT08.S4 (tungsten oxide) hourly averaged sensor response (nominally NO2 targeted)\\t\\r\\n11 PT08.S5 (indium oxide) hourly averaged sensor response (nominally O3 targeted)\\r\\n12 Temperature in Â°C\\t\\r\\n13 Relative Humidity (%) \\t\\r\\n14 AH Absolute Humidity\\r\\n', 'citation': None}}\n",
            "             name     role         type demographic  \\\n",
            "0            Date  Feature         Date        None   \n",
            "1            Time  Feature  Categorical        None   \n",
            "2          CO(GT)  Feature      Integer        None   \n",
            "3     PT08.S1(CO)  Feature  Categorical        None   \n",
            "4        NMHC(GT)  Feature      Integer        None   \n",
            "5        C6H6(GT)  Feature   Continuous        None   \n",
            "6   PT08.S2(NMHC)  Feature  Categorical        None   \n",
            "7         NOx(GT)  Feature      Integer        None   \n",
            "8    PT08.S3(NOx)  Feature  Categorical        None   \n",
            "9         NO2(GT)  Feature      Integer        None   \n",
            "10   PT08.S4(NO2)  Feature  Categorical        None   \n",
            "11    PT08.S5(O3)  Feature  Categorical        None   \n",
            "12              T  Feature   Continuous        None   \n",
            "13             RH  Feature   Continuous        None   \n",
            "14             AH  Feature   Continuous        None   \n",
            "\n",
            "                                          description       units  \\\n",
            "0                                                None        None   \n",
            "1                                                None        None   \n",
            "2   True hourly averaged concentration CO in mg/m^...      mg/m^3   \n",
            "3   hourly averaged sensor response (nominally  CO...        None   \n",
            "4   True hourly averaged overall Non Metanic Hydro...  microg/m^3   \n",
            "5   True hourly averaged Benzene concentration  in...  microg/m^3   \n",
            "6   hourly averaged sensor response (nominally NMH...        None   \n",
            "7   True hourly averaged NOx concentration  in ppb...         ppb   \n",
            "8   hourly averaged sensor response (nominally NOx...        None   \n",
            "9   True hourly averaged NO2 concentration in micr...  microg/m^3   \n",
            "10  hourly averaged sensor response (nominally NO2...        None   \n",
            "11  hourly averaged sensor response (nominally O3 ...        None   \n",
            "12                                        Temperature          °C   \n",
            "13                                  Relative Humidity           %   \n",
            "14                                  Absolute Humidity        None   \n",
            "\n",
            "   missing_values  \n",
            "0              no  \n",
            "1              no  \n",
            "2              no  \n",
            "3              no  \n",
            "4              no  \n",
            "5              no  \n",
            "6              no  \n",
            "7              no  \n",
            "8              no  \n",
            "9              no  \n",
            "10             no  \n",
            "11             no  \n",
            "12             no  \n",
            "13             no  \n",
            "14             no  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo.fetch import *"
      ],
      "metadata": {
        "id": "rlKSwmbErmr7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class dotdict(dict):\n",
        "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
        "    __getattr__ = dict.get\n",
        "    __setattr__ = dict.__setitem__\n",
        "    __delattr__ = dict.__delitem__"
      ],
      "metadata": {
        "id": "JbW5zBfgrn2j"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from typing import Optional\n",
        "import urllib.request\n",
        "import urllib.parse\n",
        "import certifi\n",
        "import ssl\n",
        "\n",
        "from ucimlrepo.dotdict import dotdict\n",
        "\n",
        "\n",
        "# constants\n",
        "\n",
        "# API endpoints\n",
        "API_BASE_URL = 'https://archive.ics.uci.edu/api/dataset'\n",
        "API_LIST_URL = 'https://archive.ics.uci.edu/api/datasets/list'\n",
        "\n",
        "# base location of data csv files\n",
        "DATASET_FILE_BASE_URL = 'https://archive.ics.uci.edu/static/public'\n",
        "\n",
        "# available categories of datasets to filter by\n",
        "VALID_FILTERS = ['aim-ahead']\n",
        "\n",
        "\n",
        "# custom exception for no dataset found during fetch_ucirepo\n",
        "class DatasetNotFoundError(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "def fetch_ucirepo(\n",
        "        name: Optional[str] = None,\n",
        "        id: Optional[int] = None\n",
        "    ):\n",
        "    '''\n",
        "    Loads a dataset from the UCI ML Repository, including the dataframes and metadata information.\n",
        "\n",
        "    Parameters:\n",
        "        id (int): Dataset ID for UCI ML Repository\n",
        "        name (str): Dataset name, or substring of name\n",
        "        (Only provide id or name, not both)\n",
        "\n",
        "    Returns:\n",
        "        result (dotdict): object containing dataset metadata, dataframes, and variable info in its properties\n",
        "    '''\n",
        "\n",
        "    # check that only one argument is provided\n",
        "    if name and id:\n",
        "        raise ValueError('Only specify either dataset name or ID, not both')\n",
        "\n",
        "    # validate types of arguments and add them to the endpoint query string\n",
        "    api_url = API_BASE_URL\n",
        "    if name:\n",
        "        if type(name) != str:\n",
        "            raise ValueError('Name must be a string')\n",
        "        api_url += '?name=' + urllib.parse.quote(name)\n",
        "    elif id:\n",
        "        if type(id) != int:\n",
        "            raise ValueError('ID must be an integer')\n",
        "        api_url += '?id=' + str(id)\n",
        "    else:\n",
        "        # no arguments provided\n",
        "        raise ValueError('Must provide a dataset name or ID')\n",
        "\n",
        "\n",
        "    # fetch metadata from API\n",
        "    data = None\n",
        "    try:\n",
        "        response = urllib.request.urlopen(api_url, context=ssl.create_default_context(cafile=certifi.where()))\n",
        "        data = json.load(response)\n",
        "    except (urllib.error.URLError, urllib.error.HTTPError):\n",
        "        raise ConnectionError('Error connecting to server')\n",
        "\n",
        "    # verify that dataset exists\n",
        "    if data['status'] != 200:\n",
        "        error_msg = data['message'] if 'message' in data else 'Dataset not found in repository'\n",
        "        raise DatasetNotFoundError(error_msg)\n",
        "\n",
        "\n",
        "    # extract ID, name, and URL from metadata\n",
        "    metadata = data['data']\n",
        "    if not id:\n",
        "        id = metadata['uci_id']\n",
        "    elif not name:\n",
        "        name = metadata['name']\n",
        "\n",
        "    data_url = metadata['data_url']\n",
        "\n",
        "    # no data URL means that the dataset cannot be imported into Python\n",
        "    # i.e. it does not yet have a standardized CSV file for pandas to parse\n",
        "    if not data_url:\n",
        "        raise DatasetNotFoundError('\"{}\" dataset (id={}) exists in the repository, but is not available for import. Please select a dataset from this list: https://archive.ics.uci.edu/datasets?skip=0&take=10&sort=desc&orderBy=NumHits&search=&Python=true'.format(name, id))\n",
        "\n",
        "\n",
        "    # parse into dataframe using pandas\n",
        "    df = None\n",
        "    try:\n",
        "        df = pd.read_csv(data_url)\n",
        "    except (urllib.error.URLError, urllib.error.HTTPError):\n",
        "        raise DatasetNotFoundError('Error reading data csv file for \"{}\" dataset (id={}).'.format(name, id))\n",
        "\n",
        "    if df.empty:\n",
        "        raise DatasetNotFoundError('Error reading data csv file for \"{}\" dataset (id={}).'.format(name, id))\n",
        "\n",
        "\n",
        "    # header line should be variable names\n",
        "    headers = df.columns\n",
        "\n",
        "    # feature information, class labels\n",
        "    variables = metadata['variables']\n",
        "    del metadata['variables']      # moved from metadata to a separate property\n",
        "\n",
        "    # organize variables into IDs, features, or targets\n",
        "    variables_by_role = {\n",
        "        'ID': [],\n",
        "        'Feature': [],\n",
        "        'Target': [],\n",
        "        'Other': []\n",
        "    }\n",
        "    for variable in variables:\n",
        "        if variable['role'] not in variables_by_role:\n",
        "            raise ValueError('Role must be one of \"ID\", \"Feature\", or \"Target\", or \"Other\"')\n",
        "        variables_by_role[variable['role']].append(variable['name'])\n",
        "\n",
        "    # extract dataframes for each variable role\n",
        "    ids_df = df[variables_by_role['ID']] if len(variables_by_role['ID']) > 0 else None\n",
        "    features_df = df[variables_by_role['Feature']] if len(variables_by_role['Feature']) > 0 else None\n",
        "    targets_df = df[variables_by_role['Target']] if len(variables_by_role['Target']) > 0 else None\n",
        "\n",
        "    # place all varieties of dataframes in data object\n",
        "    data = {\n",
        "        'ids': ids_df,\n",
        "        'features': features_df,\n",
        "        'targets': targets_df,\n",
        "        'original': df,\n",
        "        'headers': headers,\n",
        "    }\n",
        "\n",
        "    # convert variables from JSON structure to tabular structure for easier visualization\n",
        "    variables = pd.DataFrame.from_records(variables)\n",
        "\n",
        "    # alternative usage?:\n",
        "    # variables.age.role or variables.slope.description\n",
        "    # print(variables) -> json-like dict with keys [name] -> details\n",
        "\n",
        "    # make nested metadata fields accessible via dot notation\n",
        "    metadata['additional_info'] = dotdict(metadata['additional_info']) if metadata['additional_info'] else None\n",
        "    metadata['intro_paper'] = dotdict(metadata['intro_paper']) if metadata['intro_paper'] else None\n",
        "\n",
        "    # construct result object\n",
        "    result = {\n",
        "        'data': dotdict(data),\n",
        "        'metadata': dotdict(metadata),\n",
        "        'variables': variables\n",
        "    }\n",
        "\n",
        "    # convert to dictionary with dot notation\n",
        "    return dotdict(result)\n",
        "\n",
        "\n",
        "\n",
        "def list_available_datasets(filter: Optional[str] = None, search: Optional[str] = None, area: Optional[str] = None):\n",
        "    '''\n",
        "    Prints a list of datasets that can be imported via fetch_ucirepo function\n",
        "\n",
        "    Parameters:\n",
        "        filter (str): Optional query to filter available datasets based on a label\n",
        "        search (str): Optional query to search for available datasets by name\n",
        "        area (str): Optional query to filter available datasets based on subject area\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    '''\n",
        "\n",
        "    # validate filter input\n",
        "    if filter:\n",
        "        if type(filter) != str:\n",
        "            raise ValueError('Filter must be a string')\n",
        "        filter = filter.lower()\n",
        "\n",
        "    # validate search input\n",
        "    if search:\n",
        "        if type(search) != str:\n",
        "            raise ValueError('Search query must be a string')\n",
        "        search = search.lower()\n",
        "\n",
        "    # construct endpoint URL\n",
        "    api_list_url = API_LIST_URL\n",
        "    query_params = {}\n",
        "    if filter:\n",
        "        query_params['filter'] = filter\n",
        "    else:\n",
        "        query_params['filter'] = 'python'       # default filter should be 'python'\n",
        "    if search:\n",
        "        query_params['search'] = search\n",
        "    if area:\n",
        "        query_params['area'] = area\n",
        "\n",
        "    api_list_url += '?' + urllib.parse.urlencode(query_params)\n",
        "\n",
        "    # fetch list of datasets from API\n",
        "    data = None\n",
        "    try:\n",
        "        response  = urllib.request.urlopen(api_list_url, context=ssl.create_default_context(cafile=certifi.where()))\n",
        "        resp_json = json.load(response)\n",
        "    except (urllib.error.URLError, urllib.error.HTTPError):\n",
        "        raise ConnectionError('Error connecting to server')\n",
        "\n",
        "    if resp_json['status'] != 200:\n",
        "        error_msg = resp_json['message'] if 'message' in resp_json else 'Internal Server Error'\n",
        "        raise ValueError(resp_json['message'])\n",
        "\n",
        "    data = resp_json['data']\n",
        "\n",
        "    if len(data) == 0:\n",
        "        print('No datasets found')\n",
        "        return\n",
        "\n",
        "    # column width for dataset name\n",
        "    maxNameLen = max(max([len(dataset['name']) for dataset in data]) + 3, 15)\n",
        "\n",
        "    # print table title\n",
        "    title = 'The following {}datasets are available{}:'.format(filter + ' ' if filter else '', ' for search query \"{}\"'.format(search) if search else '')\n",
        "    print('-' * len(title))\n",
        "    print(title)\n",
        "    if area:\n",
        "        print('For subject area: {}'.format(area))\n",
        "    print('-' * len(title))\n",
        "\n",
        "    # print table headers\n",
        "    header_str = '{:<{width}} {:<6}'.format('Dataset Name', 'ID', width=maxNameLen)\n",
        "    underline_str = '{:<{width}} {:<6}'.format('------------', '--', width=maxNameLen)\n",
        "    if len(data) > 0 and 'description' in data[0]:\n",
        "        header_str += ' {:<100}'.format('Prediction Task')\n",
        "        underline_str += ' {:<100}'.format('---------------')\n",
        "    print(header_str)\n",
        "    print(underline_str)\n",
        "\n",
        "    # print row for each dataset\n",
        "    for dataset in data:\n",
        "        row_str = '{:<{width}} {:<6}'.format(dataset['name'], dataset['id'], width=maxNameLen)\n",
        "        if 'description' in dataset:\n",
        "            row_str += ' {:<100}'.format(dataset['description'])\n",
        "        print(row_str)\n",
        "\n",
        "    print()"
      ],
      "metadata": {
        "id": "hZ-LHGDOrtts"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.\n",
        "\n",
        "    1.Load Data:\n",
        "\n",
        "    Load air quality data from a CSV file.\n",
        "    Ensure it contains a timestamp column and an AQI column (or similar pollutant measure).\n",
        "    2.Extract Day of the Week:\n",
        "\n",
        "    Convert the timestamp column to a datetime format and extract the day of the week.\n",
        "    3.Aggregate Data:\n",
        "\n",
        "    Group AQI values by days of the week and compute the average for each day.\n",
        "    4.Identify the Worst Day:\n",
        "\n",
        "    Find the day with the highest average AQI.\n",
        "    5.Visualization:\n",
        "\n",
        "    A bar chart visualizes the average AQI for each day, highlighting patterns."
      ],
      "metadata": {
        "id": "UIl0sA8judLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ucimlrepo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtZfcz2pvNXd",
        "outputId": "c4641b03-a938-48e8-f421-a09e3eea3f75"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.10/dist-packages (0.0.7)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2024.8.30)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "air_quality = fetch_ucirepo(id=360)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = air_quality.data.features\n",
        "y = air_quality.data.targets\n",
        "\n",
        "# metadata\n",
        "print(air_quality.metadata)\n",
        "\n",
        "# variable information\n",
        "print(air_quality.variables)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yw_EvzFvQOb",
        "outputId": "543ce514-ab71-4f15-87de-ec0aafc97b82"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'uci_id': 360, 'name': 'Air Quality', 'repository_url': 'https://archive.ics.uci.edu/dataset/360/air+quality', 'data_url': 'https://archive.ics.uci.edu/static/public/360/data.csv', 'abstract': 'Contains the responses of a gas multisensor device deployed on the field in an Italian city. Hourly responses averages are recorded along with gas concentrations references from a certified analyzer. ', 'area': 'Computer Science', 'tasks': ['Regression'], 'characteristics': ['Multivariate', 'Time-Series'], 'num_instances': 9358, 'num_features': 15, 'feature_types': ['Real'], 'demographics': [], 'target_col': None, 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2008, 'last_updated': 'Sun Mar 10 2024', 'dataset_doi': '10.24432/C59K5F', 'creators': ['Saverio Vito'], 'intro_paper': {'ID': 420, 'type': 'NATIVE', 'title': 'On field calibration of an electronic nose for benzene estimation in an urban pollution monitoring scenario', 'authors': 'S. D. Vito, E. Massera, M. Piga, L. Martinotto, G. Francia', 'venue': 'Sensors and Actuators B: Chemical', 'year': 2008, 'journal': None, 'DOI': '10.1016/j.snb.2007.09.060', 'URL': 'https://www.semanticscholar.org/paper/a90a54a39ff934772df57771a0012981f355949d', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'The dataset contains 9358 instances of hourly averaged responses from an array of 5 metal oxide chemical sensors embedded in an Air Quality Chemical Multisensor Device. The device was located on the field in a significantly polluted area, at road level,within an Italian city. Data were recorded from March 2004 to February 2005 (one year)representing the longest freely available recordings of on field deployed air quality chemical sensor devices responses. Ground Truth hourly averaged concentrations for CO, Non Metanic Hydrocarbons, Benzene, Total Nitrogen Oxides (NOx) and Nitrogen Dioxide (NO2)  and were provided by a co-located reference certified analyzer. Evidences of cross-sensitivities as well as both concept and sensor drifts are present as described in De Vito et al., Sens. And Act. B, Vol. 129,2,2008 (citation required) eventually affecting sensors concentration estimation capabilities. Missing values are tagged with -200 value.\\r\\nThis dataset can be used exclusively for research purposes. Commercial purposes are fully excluded.\\r\\n', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': '0 Date\\t(DD/MM/YYYY)\\r\\n1 Time\\t(HH.MM.SS)\\r\\n2 True hourly averaged concentration CO in mg/m^3  (reference analyzer)\\r\\n3 PT08.S1 (tin oxide)  hourly averaged sensor response (nominally  CO targeted)\\t\\r\\n4 True hourly averaged overall Non Metanic HydroCarbons concentration in microg/m^3 (reference analyzer)\\r\\n5 True hourly averaged Benzene concentration  in microg/m^3 (reference analyzer)\\r\\n6 PT08.S2 (titania) hourly averaged sensor response (nominally NMHC targeted)\\t\\r\\n7 True hourly averaged NOx concentration  in ppb (reference analyzer)\\r\\n8 PT08.S3 (tungsten oxide) hourly averaged sensor response (nominally NOx targeted) \\r\\n9 True hourly averaged NO2 concentration in microg/m^3 (reference analyzer)\\t\\r\\n10 PT08.S4 (tungsten oxide) hourly averaged sensor response (nominally NO2 targeted)\\t\\r\\n11 PT08.S5 (indium oxide) hourly averaged sensor response (nominally O3 targeted)\\r\\n12 Temperature in Â°C\\t\\r\\n13 Relative Humidity (%) \\t\\r\\n14 AH Absolute Humidity\\r\\n', 'citation': None}}\n",
            "             name     role         type demographic  \\\n",
            "0            Date  Feature         Date        None   \n",
            "1            Time  Feature  Categorical        None   \n",
            "2          CO(GT)  Feature      Integer        None   \n",
            "3     PT08.S1(CO)  Feature  Categorical        None   \n",
            "4        NMHC(GT)  Feature      Integer        None   \n",
            "5        C6H6(GT)  Feature   Continuous        None   \n",
            "6   PT08.S2(NMHC)  Feature  Categorical        None   \n",
            "7         NOx(GT)  Feature      Integer        None   \n",
            "8    PT08.S3(NOx)  Feature  Categorical        None   \n",
            "9         NO2(GT)  Feature      Integer        None   \n",
            "10   PT08.S4(NO2)  Feature  Categorical        None   \n",
            "11    PT08.S5(O3)  Feature  Categorical        None   \n",
            "12              T  Feature   Continuous        None   \n",
            "13             RH  Feature   Continuous        None   \n",
            "14             AH  Feature   Continuous        None   \n",
            "\n",
            "                                          description       units  \\\n",
            "0                                                None        None   \n",
            "1                                                None        None   \n",
            "2   True hourly averaged concentration CO in mg/m^...      mg/m^3   \n",
            "3   hourly averaged sensor response (nominally  CO...        None   \n",
            "4   True hourly averaged overall Non Metanic Hydro...  microg/m^3   \n",
            "5   True hourly averaged Benzene concentration  in...  microg/m^3   \n",
            "6   hourly averaged sensor response (nominally NMH...        None   \n",
            "7   True hourly averaged NOx concentration  in ppb...         ppb   \n",
            "8   hourly averaged sensor response (nominally NOx...        None   \n",
            "9   True hourly averaged NO2 concentration in micr...  microg/m^3   \n",
            "10  hourly averaged sensor response (nominally NO2...        None   \n",
            "11  hourly averaged sensor response (nominally O3 ...        None   \n",
            "12                                        Temperature          °C   \n",
            "13                                  Relative Humidity           %   \n",
            "14                                  Absolute Humidity        None   \n",
            "\n",
            "   missing_values  \n",
            "0              no  \n",
            "1              no  \n",
            "2              no  \n",
            "3              no  \n",
            "4              no  \n",
            "5              no  \n",
            "6              no  \n",
            "7              no  \n",
            "8              no  \n",
            "9              no  \n",
            "10             no  \n",
            "11             no  \n",
            "12             no  \n",
            "13             no  \n",
            "14             no  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.)\n",
        "\n",
        "    1.Load Data: The script assumes your dataset is a CSV file and includes an AQI column with numeric values representing air quality levels.\n",
        "    2.Identify Max and Min Values:\n",
        "    Use max() and idxmax() to get the maximum AQI value and the corresponding row.\n",
        "    Use min() and idxmin() for the minimum AQI value.\n",
        "    3.Output:\n",
        "    The maximum and minimum AQI values are displayed along with their details (e.g., timestamp, location)."
      ],
      "metadata": {
        "id": "EE1bZRqsv52j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcLdxYtwwsDX",
        "outputId": "52643565-6c61-419e-818c-56401d5ca815"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.)\n",
        "\n",
        "    1.Dataset Requirements:\n",
        "\n",
        "    A column with temperature values (temperature).\n",
        "    Optionally, a column with timestamps (timestamp) for context.\n",
        "    2.Finding Maximum and Minimum Temperatures:\n",
        "\n",
        "    max() and idxmax() are used to find the highest temperature and its corresponding row in the dataset.\n",
        "    min() and idxmin() are used similarly for the lowest temperature.\n",
        "    3.Output:\n",
        "\n",
        "    The script displays the highest and lowest temperatures along with additional details like timestamp or location (if included in the dataset)."
      ],
      "metadata": {
        "id": "Wi618-dpx3Lu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.)\n",
        "\n",
        "    1.Load the Dataset:\n",
        "\n",
        "    A CSV file containing employee details, including an education column (qualification).\n",
        "    2.Check Unique Qualifications:\n",
        "\n",
        "    Ensures consistency in formatting, as inconsistent data (e.g., \"Bachelors\" vs. \"Bachelor's\") might require cleaning.\n",
        "    3.Define Qualification Hierarchy:\n",
        "\n",
        "    A predefined order of qualifications is used to determine the highest level. Customize the list based on your dataset.\n",
        "    4.Categorize Qualifications:\n",
        "\n",
        "    Assigns a categorical type with the hierarchy for ordered comparisons.\n",
        "    5.Find the Highest Qualification:\n",
        "\n",
        "    Identifies the maximum qualification and lists employees who hold it."
      ],
      "metadata": {
        "id": "d-EVDSbZynHu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.)\n",
        "\n",
        "    Classification: Use if the dataset includes labeled data (e.g., predicting educational qualification based on features like age, department, etc.).\n",
        "    Clustering: Use if the dataset lacks labels and you aim to group employees with similar characteristics."
      ],
      "metadata": {
        "id": "-HWI5spRy0qP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ucimlrepo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ci0G3PlZzSYt",
        "outputId": "2528af86-32a0-4c70-c043-5c8cbb6d8f02"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.10/dist-packages (0.0.7)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2024.8.30)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "air_quality = fetch_ucirepo(id=360)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = air_quality.data.features\n",
        "y = air_quality.data.targets\n",
        "\n",
        "# metadata\n",
        "print(air_quality.metadata)\n",
        "\n",
        "# variable information\n",
        "print(air_quality.variables)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfCDabcyzWJO",
        "outputId": "99a6f2a7-5fce-4c8d-bd4d-584dc173340a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'uci_id': 360, 'name': 'Air Quality', 'repository_url': 'https://archive.ics.uci.edu/dataset/360/air+quality', 'data_url': 'https://archive.ics.uci.edu/static/public/360/data.csv', 'abstract': 'Contains the responses of a gas multisensor device deployed on the field in an Italian city. Hourly responses averages are recorded along with gas concentrations references from a certified analyzer. ', 'area': 'Computer Science', 'tasks': ['Regression'], 'characteristics': ['Multivariate', 'Time-Series'], 'num_instances': 9358, 'num_features': 15, 'feature_types': ['Real'], 'demographics': [], 'target_col': None, 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2008, 'last_updated': 'Sun Mar 10 2024', 'dataset_doi': '10.24432/C59K5F', 'creators': ['Saverio Vito'], 'intro_paper': {'ID': 420, 'type': 'NATIVE', 'title': 'On field calibration of an electronic nose for benzene estimation in an urban pollution monitoring scenario', 'authors': 'S. D. Vito, E. Massera, M. Piga, L. Martinotto, G. Francia', 'venue': 'Sensors and Actuators B: Chemical', 'year': 2008, 'journal': None, 'DOI': '10.1016/j.snb.2007.09.060', 'URL': 'https://www.semanticscholar.org/paper/a90a54a39ff934772df57771a0012981f355949d', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'The dataset contains 9358 instances of hourly averaged responses from an array of 5 metal oxide chemical sensors embedded in an Air Quality Chemical Multisensor Device. The device was located on the field in a significantly polluted area, at road level,within an Italian city. Data were recorded from March 2004 to February 2005 (one year)representing the longest freely available recordings of on field deployed air quality chemical sensor devices responses. Ground Truth hourly averaged concentrations for CO, Non Metanic Hydrocarbons, Benzene, Total Nitrogen Oxides (NOx) and Nitrogen Dioxide (NO2)  and were provided by a co-located reference certified analyzer. Evidences of cross-sensitivities as well as both concept and sensor drifts are present as described in De Vito et al., Sens. And Act. B, Vol. 129,2,2008 (citation required) eventually affecting sensors concentration estimation capabilities. Missing values are tagged with -200 value.\\r\\nThis dataset can be used exclusively for research purposes. Commercial purposes are fully excluded.\\r\\n', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': '0 Date\\t(DD/MM/YYYY)\\r\\n1 Time\\t(HH.MM.SS)\\r\\n2 True hourly averaged concentration CO in mg/m^3  (reference analyzer)\\r\\n3 PT08.S1 (tin oxide)  hourly averaged sensor response (nominally  CO targeted)\\t\\r\\n4 True hourly averaged overall Non Metanic HydroCarbons concentration in microg/m^3 (reference analyzer)\\r\\n5 True hourly averaged Benzene concentration  in microg/m^3 (reference analyzer)\\r\\n6 PT08.S2 (titania) hourly averaged sensor response (nominally NMHC targeted)\\t\\r\\n7 True hourly averaged NOx concentration  in ppb (reference analyzer)\\r\\n8 PT08.S3 (tungsten oxide) hourly averaged sensor response (nominally NOx targeted) \\r\\n9 True hourly averaged NO2 concentration in microg/m^3 (reference analyzer)\\t\\r\\n10 PT08.S4 (tungsten oxide) hourly averaged sensor response (nominally NO2 targeted)\\t\\r\\n11 PT08.S5 (indium oxide) hourly averaged sensor response (nominally O3 targeted)\\r\\n12 Temperature in Â°C\\t\\r\\n13 Relative Humidity (%) \\t\\r\\n14 AH Absolute Humidity\\r\\n', 'citation': None}}\n",
            "             name     role         type demographic  \\\n",
            "0            Date  Feature         Date        None   \n",
            "1            Time  Feature  Categorical        None   \n",
            "2          CO(GT)  Feature      Integer        None   \n",
            "3     PT08.S1(CO)  Feature  Categorical        None   \n",
            "4        NMHC(GT)  Feature      Integer        None   \n",
            "5        C6H6(GT)  Feature   Continuous        None   \n",
            "6   PT08.S2(NMHC)  Feature  Categorical        None   \n",
            "7         NOx(GT)  Feature      Integer        None   \n",
            "8    PT08.S3(NOx)  Feature  Categorical        None   \n",
            "9         NO2(GT)  Feature      Integer        None   \n",
            "10   PT08.S4(NO2)  Feature  Categorical        None   \n",
            "11    PT08.S5(O3)  Feature  Categorical        None   \n",
            "12              T  Feature   Continuous        None   \n",
            "13             RH  Feature   Continuous        None   \n",
            "14             AH  Feature   Continuous        None   \n",
            "\n",
            "                                          description       units  \\\n",
            "0                                                None        None   \n",
            "1                                                None        None   \n",
            "2   True hourly averaged concentration CO in mg/m^...      mg/m^3   \n",
            "3   hourly averaged sensor response (nominally  CO...        None   \n",
            "4   True hourly averaged overall Non Metanic Hydro...  microg/m^3   \n",
            "5   True hourly averaged Benzene concentration  in...  microg/m^3   \n",
            "6   hourly averaged sensor response (nominally NMH...        None   \n",
            "7   True hourly averaged NOx concentration  in ppb...         ppb   \n",
            "8   hourly averaged sensor response (nominally NOx...        None   \n",
            "9   True hourly averaged NO2 concentration in micr...  microg/m^3   \n",
            "10  hourly averaged sensor response (nominally NO2...        None   \n",
            "11  hourly averaged sensor response (nominally O3 ...        None   \n",
            "12                                        Temperature          °C   \n",
            "13                                  Relative Humidity           %   \n",
            "14                                  Absolute Humidity        None   \n",
            "\n",
            "   missing_values  \n",
            "0              no  \n",
            "1              no  \n",
            "2              no  \n",
            "3              no  \n",
            "4              no  \n",
            "5              no  \n",
            "6              no  \n",
            "7              no  \n",
            "8              no  \n",
            "9              no  \n",
            "10             no  \n",
            "11             no  \n",
            "12             no  \n",
            "13             no  \n",
            "14             no  \n"
          ]
        }
      ]
    }
  ]
}